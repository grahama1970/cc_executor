--- a/src/cc_executor/client/cc_execute.py
+++ b/src/cc_executor/client/cc_execute.py
@@ -291,7 +291,7 @@ async def _execute_claude_command(
         env=env,  # Use our enhanced environment (NO API KEY - browser auth)
         # Match websocket_handler.py process group handling
         preexec_fn=os.setsid if os.name != 'nt' else None,
-        limit=8 * 1024 * 1024  # 8MB buffer limit for large outputs
+        # Don't set a limit - let the OS handle it
     )
     logger.info(f"[{session_id}] Subprocess created with PID: {proc.pid}")
     
@@ -304,33 +304,29 @@ async def _execute_claude_command(
             # Stream output in real-time with timeout
             # Create tasks for reading stdout and stderr
             async def read_stream(stream, target_list, prefix=""):
-                """Read from stream line by line."""
-                while True:
-                    line = await stream.readline()
-                    if not line:
-                        break
-                    decoded = line.decode('utf-8', errors='replace')
-                    target_list.append(decoded)
-                    # Stream to console with session ID
-                    print(f"[{session_id}] {decoded}", end='')
-                    
-                    # Report progress
-                    if progress_callback and any(indicator in decoded.lower() for indicator in 
-                                               ['complete', 'done', 'finish', 'success']):
-                        await progress_callback(f"Progress: {decoded.strip()[:100]}")
-                    
-                    # Smart logging - truncate large data
-                    log_line = decoded.strip()
-                    if len(log_line) > 200:
-                        # Check for base64/embeddings
-                        if any(marker in log_line for marker in ['data:image/', 'base64,', 'embedding:', 'vector:']):
-                            log_line = f"[BINARY/EMBEDDING DATA - {len(log_line)} chars]"
-                        else:
-                            log_line = log_line[:200] + f"... [{len(log_line)-200} chars truncated]"
-                    
-                    # Log progress indicators and truncated content
-                    if any(indicator in decoded.lower() for indicator in 
-                           ['complete', 'done', 'finish', 'success', 'fail', 'error']):
-                        logger.info(f"[{session_id}] Progress: {log_line}")
+                """Read from stream in CHUNKS, not lines!"""
+                try:
+                    while True:
+                        # CRITICAL FIX: Read chunks, not lines!
+                        chunk = await stream.read(8192)  # 8KB chunks
+                        if not chunk:
+                            break
+                        
+                        # Store raw bytes
+                        target_list.append(chunk)
+                        
+                        # Stream to console if requested
+                        if config.stream_output:
+                            try:
+                                decoded = chunk.decode('utf-8', errors='replace')
+                                print(f"[{session_id}] {prefix}{decoded}", end='', flush=True)
+                            except:
+                                pass  # Don't fail on decode errors
+                                
+                        # Don't try to parse lines - we're reading chunks!
+                        
+                except Exception as e:
+                    logger.error(f"Error reading {prefix}: {e}")
             
             # Create concurrent tasks for stdout/stderr
             logger.debug(f"[{session_id}] Starting stream readers")
@@ -389,10 +385,23 @@ async def _execute_claude_command(
                 timeout=config.timeout
             )
             
+            # CRITICAL: Convert bytes to string AFTER reading
             if stdout:
-                output_lines = stdout.decode().splitlines(keepends=True)
+                output_lines = [stdout.decode('utf-8', errors='replace')]
             if stderr:
-                error_lines = stderr.decode().splitlines(keepends=True)
+                error_lines = [stderr.decode('utf-8', errors='replace')]
+    
+    # If we collected chunks, decode them
+    if stream and config.stream_output and output_lines:
+        # output_lines contains chunks of bytes
+        stdout_data = b''.join(output_lines)
+        stderr_data = b''.join(error_lines) if error_lines else b''
+        
+        # Convert to string lines
+        output_lines = stdout_data.decode('utf-8', errors='replace').splitlines(keepends=True)
+        error_lines = stderr_data.decode('utf-8', errors='replace').splitlines(keepends=True)
+        
+        # Handle case where there are no newlines
+        if stdout_data and not output_lines:
+            output_lines = [stdout_data.decode('utf-8', errors='replace')]
             
             if progress_callback:
                 await progress_callback("Claude execution completed")