# Core Assessment Report Template

This template defines the structure for core module assessment reports that include both automated testing results and Claude's manual reasonableness assessments.

## Report Metadata
```yaml
Report Type: Core Module Assessment
Generated By: Automated Script + Claude Analysis
Template Version: 1.0
Purpose: Verify all core components have functioning usage examples
```

## Required Sections

### 1. Report Header
```markdown
# Core Components Usage Assessment Report
Generated: {timestamp}
Session ID: {session_id}
Assessed by: Claude (Script: assess_all_core_usage.py + Manual Analysis)
Template: docs/templates/CORE_ASSESSMENT_REPORT_TEMPLATE.md v1.0
```

### 2. Executive Summary
```markdown
## Summary
- Total Components Tested: {count}
- Automated Pass Rate: {auto_pass_rate}%
- Claude's Verified Pass Rate: {claude_pass_rate}%
- Critical Component (websocket_handler.py): {status}
- System Health: {overall_assessment}
```

### 3. Component Assessment Format

Each component MUST include both automated results AND Claude's analysis:

```markdown
### {icon} {filename}

#### Automated Test Results
- **Exit Code**: {code}
- **Execution Time**: {time}s  
- **Output Lines**: {lines}
- **Expected Indicators Found**: {indicators}
- **Contains Numbers**: {yes/no}

#### ðŸ§  Claude's Reasonableness Assessment
**Verdict**: [REASONABLE/UNREASONABLE/SUSPICIOUS]

**Expected vs Actual**:
- **Expected**: {what the component should demonstrate}
- **Observed**: {what the output actually shows}

**Evidence Analysis**:
âœ“ {specific evidence point that proves functionality}
âœ“ {another specific evidence point}
âœ— {anything missing or concerning}

**Numerical Validation**:
- {analysis of any numbers in output - are they sensible?}
- {e.g., "PID 806282 is valid Linux process ID"}
- {e.g., "CPU usage 5.0% is realistic for idle system"}

**Conclusion**: {1-2 sentences on whether this proves the component works}

#### Output Sample
```
{output}
```
```

### 4. Overall System Assessment

```markdown
## ðŸŽ¯ Claude's Overall System Assessment

### System Health Analysis
Based on the outputs, I assess the cc_executor core system as: [HEALTHY/DEGRADED/FAILING]

**Key Observations**:
1. {Major finding from outputs}
2. {Pattern noticed across components}
3. {Any concerning indicators}

### Confidence in Results
**Confidence Level**: [HIGH/MEDIUM/LOW]

**Reasoning**: {Why I have this confidence level based on the evidence}

### Risk Assessment
- **Immediate Risks**: {Any critical issues found}
- **Potential Issues**: {Things that might become problems}
- **Unknown Factors**: {What couldn't be verified}
```

### 5. Recommendations

```markdown
## ðŸ“‹ Recommendations

### Immediate Actions
1. {Critical fixes needed based on assessment}

### Improvements
1. {Suggested enhancements based on output analysis}

### Future Monitoring
1. {What to watch for in future assessments}
```

## Assessment Guidelines for Claude

### What Makes Output "REASONABLE"?
1. **Functional Demonstration**: Output shows the component doing its intended job
2. **Valid Data**: Numbers are in expected ranges, strings match expected formats
3. **No Unexpected Errors**: No stack traces unless testing error handling
4. **Logical Flow**: Output sequence makes sense for the operation
5. **Performance**: Execution times are appropriate for the task

### Red Flags to Check
- ðŸš¨ Infinite loops or recursion indicators
- ðŸš¨ Memory/resource warnings
- ðŸš¨ Permission or access errors
- ðŸš¨ Missing expected functionality
- ðŸš¨ Suspicious timing (too fast/slow)

### Number Validation Checklist
- [ ] Process IDs: Valid range (1-32768 typical)
- [ ] Ports: Valid range (1-65535)
- [ ] Percentages: 0-100%
- [ ] Timeouts: Reasonable for operation type
- [ ] Memory sizes: Power of 2 typical
- [ ] Exit codes: 0=success, non-zero=error

## Example Component Assessment

### âœ… resource_monitor.py

#### Automated Test Results
- **Exit Code**: 0
- **Execution Time**: 3.37s
- **Output Lines**: 17
- **Expected Indicators Found**: cpu, resource, usage, %
- **Contains Numbers**: Yes

#### ðŸ§  Claude's Reasonableness Assessment
**Verdict**: REASONABLE

**Expected vs Actual**:
- **Expected**: CPU/GPU monitoring with dynamic timeout adjustment based on load
- **Observed**: Clear demonstration of resource monitoring and threshold-based timeout multiplication

**Evidence Analysis**:
âœ“ CPU readings (5.0%, 2.8%) are realistic for a development machine
âœ“ Timeout multiplier correctly applies 3x when CPU > 14%
âœ“ Boundary testing at exactly 14% shows proper threshold handling
âœ“ GPU at 0% is expected without active GPU tasks

**Numerical Validation**:
- CPU percentages all within valid 0-100% range
- 3.37s execution time reasonable for sampling system resources
- Timeout calculations correct: 30s â†’ 90s with 3x multiplier

**Conclusion**: Output proves the resource monitor correctly reads system metrics and adjusts timeouts based on load, which is essential for preventing premature timeout of long-running tasks.

## Template Usage Notes

1. **Every component needs Claude's assessment** - Not just pass/fail
2. **Be specific** - Reference actual values from output
3. **Explain reasoning** - Why does this output prove functionality?
4. **Check the numbers** - Validate all numerical outputs
5. **Consider the context** - What is this component's role in the system?

## Version History
- v1.0 (2025-07-03): Initial template addressing v8 failure - requires Claude's reasonableness assessments