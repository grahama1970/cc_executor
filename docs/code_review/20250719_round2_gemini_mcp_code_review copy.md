# MCP Server Suite - Technical Code Review  
_2025-07-19_

This document lists **actionable, low-risk improvements** for each MCP server,  
prioritising reliability and agent usability over new features.  
All findings are based on static analysis of the current codebase and alignment  
with the unified `servers/README.md`.

---

## Legend

| Symbol | Meaning |
| ------ | ------- |
| ðŸ”´ | Critical â€“ likely to break agent workflows |
| ðŸŸ¡ | Important â€“ can hinder reliability or debuggability |
| ðŸŸ¢ | Nice to have â€“ polish / tech-debt reduction |

Each recommendation is written so it can be applied **incrementally** without  
large-scale refactors.

---

## 1  mcp_arango_tools.py ðŸ”—

| Line Range | Severity | Finding | Recommendation |
| ---------- | -------- | ------- | -------------- |
| 289-321 | ðŸŸ¡ | `_connect()` retries only once; Arango startup lag can exceed the single attempt. | Wrap in exponential back-off (e.g. `tenacity` retry for 3-5 attempts, total â‰¤ 8 s). |
| 447-465 | ðŸŸ¡ | `execute_aql()` logs raw query text on exception â†’ secrets/PII risk. | Redact bind-vars before logging **or** add opt-in verbose flag. |
| 536-585 | ðŸ”´ | `upsert_document()` catches generic `Exception` and returns empty dict; agent cannot detect silent failure. | Re-raise after logging **or** return `{ "error": str(e) }` with `success:false`. |
| 3005-3251 | ðŸŸ¡ | `build_similarity_graph()` loads all embeddings into RAM; not chunk-aware for > 1 M docs. | Add `IndexIVFFlat` fallback after N > 250 k and stream inserts to reduce RAM spike. |
| 3431-3610 | ðŸŸ¢ | Community detection offers only Louvain; other algos commented out. | Expose `algorithm` param in MCP tool description + validate against supported list. |

### Test Coverage Gaps
* No failing-DB simulation tests; add pytest fixture that returns HTTP 503 to ensure retry path.

---

## 2  mcp_tool_journey.py ðŸ”—

| Section | Sev. | Issue | Fix |
| ------- | ---- | ----- | --- |
| Q-value helpers | ðŸŸ¡ | Thompson parameters default to `(1,1)`, causing optimistic bias on first use. | Persist neutral prior `(alpha=0.5, beta=0.5)` or configurable via env-var. |
| `record_tool_step` | ðŸ”´ | Does not cap `duration_ms`, allowing negative or extremely high values. | Validate `0 â‰¤ duration_ms â‰¤ 86 400 000`. |
| Reward calc | ðŸŸ¡ | `_calculate_reward()` duplicates logic in `mcp_outcome_adjudicator`; risk of divergence. | Import constants from single `rewards.py`. |

---

## 3  mcp_outcome_adjudicator.py ðŸ”—

| Lines | Sev. | Finding | Recommendation |
| ----- | ---- | ------- | -------------- |
| 98-131 | ðŸŸ¡ | `_check_for_hard_evidence()` treats missing `verification_result` as failure but assigns no negative reward. | Return explicit `"outcome":"verification_missing"` â†’ maps to `task_failure` reward. |
| 188-209 | ðŸ”´ | `_calculate_final_reward()` divides by `journey_context["steps"]` without zero-check. | Guard with `max(steps,1)`. |
| 242-272 (tool) | ðŸŸ¢ | Tool returns raw dict but README suggests JSON string. | Clarify spec or wrap with `json.dumps`. |

---

## 4  mcp_tool_sequence_optimizer.py ðŸ”—

* ðŸŸ¡ `optimize_tool_sequence` loads **all** `tool_journey_edges`; add pagination (`batch_size` param).  
* ðŸŸ¢ No unit tests for cold-start bootstrap; create fixture with synthetic edges.

---

## 5  mcp_debugging_assistant.py ðŸ”—

| Area | Sev. | Issue | Suggestion |
| ---- | ---- | ----- | ---------- |
| `resolve_error_workflow` | ðŸŸ¡ | Assumes Arango is reachable; no graceful degradation. | If DB unavailable, fall back to LiteLLM search and warn. |
| Workflow steps | ðŸŸ¢ | Fixed sleep `await asyncio.sleep(1)` in sample usage slows tests. | Replace with mockable delay constant. |

---

<!-- ## 6  mcp_cc_execute.py ðŸ”—
# archiving--not needed

| Section | Sev. | Finding | Recommendation |
| ------- | ---- | ------- | -------------- |
| `execute_task` | ðŸ”´ | Accepts arbitrary shell command via `task_cmd` â†’ injection risk when agent strings concatenated. | Sanitize or require list form passed to `subprocess.exec`. |
| `verify_execution` | ðŸŸ¡ | Reads large files into memory for checksum; use `hashlib.file_digest()` streamed chunks. |
| Logging | ðŸŸ¢ | Uses `print` in fallback paths; standardise on `logger`. | -->

---

## 7  mcp_llm_instance.py / mcp_litellm_*.*.py ðŸ”—

* ðŸŸ¡ `execute_llm_with_retry` uses constant back-off; switch to exponential jitter to avoid thundering-herd on rate limits.  
* ðŸŸ¡ `estimate_tokens` hard-codes 4 chars per token; adjust per-model or integrate `tiktoken` if available.  
* ðŸŸ¢ `configure_llm` lacks schema validation; add Pydantic model.

---

## 8  mcp_d3_visualization_advisor.py ðŸ”—

| Lines | Sev. | Problem | Fix |
| ----- | ---- | ------- | --- |
| 958-1060 | ðŸŸ¡ | Pandas analysis branch imports heavy libs even for non-tabular JSON. | Lazy-import pandas only when required. |
| 1395-1507 | ðŸŸ¢ | Graph metric computations are O(NÂ²) for dense graphs; add early exit for N > 5 k. |

---

## 9  mcp_d3_visualizer.py ðŸ”—

* ðŸŸ¡ Template strings embed unescaped user titles; call `html.escape`.  
* ðŸŸ¢ `_get_force_template` duplicates inline CSS; move to `static/` for caching.

---

## 10  mcp_kilocode_review.py ðŸ”—

* ðŸŸ¡ `_run_command` marks every non-zero exit as failure but discards `stderr`; capture and return for agent debugging.  
* ðŸŸ¢ Parsing routine assumes review directory contains < 8 k files; add glob size guard.

---

## 11  mcp_universal_llm_executor.py ðŸ”—

* ðŸŸ¡ `execute_llm` streams stdout but buffers stderr fully; risk of dead-lock on verbose models. Use `asyncio.create_subprocess_exec` with pipe merging.  
* ðŸŸ¢ `detect_available_llms` scans `$PATH` synchronously; offload to thread-executor.

---

## 12  README & Usage Scenarios ðŸ”—

| File | Finding |
| ---- | ------- |
| `servers/README.md` | Reward constant table matches code âœ…. Mention Thompson prior initialisation (see Tool Journey note). |
| `tests/usage_scenarios/*.md` | Scenarios rely on deprecated `data.old`; update paths when refactoring `mcp_arango_tools`. |

---

## 13  Cross-Cutting Improvements

1. **Typed Responses** ðŸ”´  
   Every MCP tool should return a typed JSON object with at minimum  
   `{ success: bool, data:â€¦, error:â€¦ }`. Current implementations vary (dict vs str).  
   Standardising simplifies agent parsing.

2. **Timeout & Cancellation** ðŸŸ¡  
   Long-running FAISS builds or LLM calls lack `asyncio.timeout`.  
   Add cooperative cancellation to avoid hanging journeys.

3. **Centralised Reward Constants** ðŸŸ¡  
   Duplicate dictionaries exist in two modules; extract to `cc_executor.servers.rewards`.

4. **Logging Consistency** ðŸŸ¢  
   Migrate scattered `print` statements to structured logging (`structlog` or similar).

---

## 14  Next Steps

1. Apply ðŸ”´ critical fixes first â€“ minimal code touch-points, highest reliability gain.  
2. Add regression tests for each critical path (connection retry, reward calc divide-by-zero, command injection).  
3. Incrementally roll out ðŸŸ¡ improvements, verifying agent end-to-end scenarios after each patch.  
4. Reserve ðŸŸ¢ items for maintenance sprint once stability goals met.

---

## 15  Appendix A â€“ Tool Return Schema (Proposed)

```json
{
  "success": true,
  "data": { "â€¦": "tool-specific payload" },
  "error": null,
  "metadata": {
    "duration_ms": 123,
    "tool": "mcp_arango_tools.query",
    "version": "2025-07-19"
  }
}
```

Adopting this schema will reduce parsing brittleness and enable uniform logging.