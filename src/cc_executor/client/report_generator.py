"""
Report generation for CC Executor.

Generates assessment reports following CORE_ASSESSMENT_REPORT_TEMPLATE.md format.
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional
import uuid


def generate_assessment_report(
    session_id: str,
    task: str,
    execution_uuid: str,
    proc_returncode: int,
    execution_time: float,
    full_output: str,
    output_lines: List[str],
    error_lines: List[str],
    response_file: Path,
    response_data: Dict[str, Any],
    config_timeout: int,
    stream: bool,
    json_mode: bool,
    amend_prompt: bool,
    estimate_timeout_func
) -> tuple[Path, str]:
    """
    Generate an assessment report following CORE_ASSESSMENT_REPORT_TEMPLATE.md.
    
    Args:
        session_id: Session identifier
        task: The task that was executed
        execution_uuid: UUID for anti-hallucination verification
        proc_returncode: Process return code (0 = success)
        execution_time: Time taken to execute in seconds
        full_output: Complete output from the process
        output_lines: List of output lines
        error_lines: List of error lines
        response_file: Path to the JSON response file
        response_data: Dictionary containing response data
        config_timeout: Configured timeout in seconds
        stream: Whether streaming was enabled
        json_mode: Whether JSON mode was enabled
        amend_prompt: Whether prompt amendment was used
        estimate_timeout_func: Function to estimate timeout for the task
        
    Returns:
        Tuple of (report_file_path, report_content)
    """
    report_uuid = str(uuid.uuid4())
    report_timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = response_file.parent / f"CC_EXECUTE_ASSESSMENT_REPORT_{timestamp}.md"
    
    # Build report following CORE_ASSESSMENT_REPORT_TEMPLATE.md
    report_content = f"""# CC_EXECUTE Assessment Report
Generated: {report_timestamp}
Session ID: {session_id}
Execution UUID: {execution_uuid}
Report UUID: {report_uuid}
Template: docs/templates/CORE_ASSESSMENT_REPORT_TEMPLATE.md v1.3

## Summary
- Task: {task}
- Exit Code: {proc_returncode}
- Execution Time: {execution_time:.2f}s
- Output Size: {len(full_output)} characters
- Timeout Used: {config_timeout}s
- Stream Mode: {stream}
- JSON Mode: {json_mode}
- Prompt Amended: {amend_prompt}

## Task Execution Assessment

### Automated Results
- **Exit Code**: {proc_returncode}
- **Execution Time**: {execution_time:.2f}s
- **Output Lines**: {len(output_lines)}
- **Error Output**: {"Yes" if error_lines else "No"}
- **Response Saved**: {response_file}

### Complete JSON Response File
```json
{json.dumps(response_data, indent=2)}
```

### Output Analysis
"""
    
    # Add JSON structure detection section
    if json_mode and isinstance(full_output, str) and 'json' in full_output.lower():
        report_content += """#### JSON Structure Detected
- JSON parsing was requested and output appears to contain JSON
- Clean JSON extraction was successful
"""
    
    # Add error output section if present
    if error_lines:
        error_preview = ''.join(error_lines[:20])
        if len(error_lines) > 20:
            error_preview += "..."
        
        report_content += f"""#### Error Output
```
{error_preview}
```
"""
    
    # Add performance metrics
    estimated_timeout = estimate_timeout_func(task)
    efficiency = (execution_time / config_timeout * 100) if config_timeout > 0 else 0
    
    report_content += f"""### Performance Metrics
- Redis Timeout Estimation: {estimated_timeout}s
- Actual Execution Time: {execution_time:.2f}s
- Efficiency: {efficiency:.1f}% of allocated timeout

### Anti-Hallucination Verification
**Report UUID**: `{report_uuid}`
**Execution UUID**: `{execution_uuid}`

These UUIDs can be verified against:
- JSON response file: {response_file}
- Transcript logs for session: {session_id}

## Verification Commands
```bash
# Verify response file exists
ls -la {response_file}

# Check execution UUID in response
jq -r '.execution_uuid' {response_file}

# Search transcripts for this execution
rg "{execution_uuid}" ~/.claude/projects/*/$(date +%Y%m%d)*.jsonl
```

## Task Completion Status
{"✅ COMPLETED" if proc_returncode == 0 else "❌ FAILED"}

Generated by cc_execute() with report generation enabled.
"""
    
    return report_file, report_content


def save_assessment_report(report_file: Path, report_content: str) -> None:
    """
    Save the assessment report to disk.
    
    Args:
        report_file: Path where to save the report
        report_content: Content of the report
    """
    with open(report_file, 'w') as f:
        f.write(report_content)